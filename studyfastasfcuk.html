<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Study Fast As Fcuk: BCA Semester 3</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <!-- Chosen Palette: Calm Neutrals -->
    <!-- Application Structure Plan: The application is structured into two primary, switchable sections: Operating Systems (C6) and Computer Networks (C7), reflecting the two exam papers. This top-level navigation allows users to focus their study. Within each section, a vertical sub-navigation menu lists all key topics from the syllabus. Clicking a topic dynamically loads its content into the main view area. This hierarchical, single-page application (SPA) design was chosen for its speed (no page reloads) and clarity, preventing information overload and allowing students to drill down into specific concepts efficiently. Interactive elements are embedded directly within relevant topic sections to connect theory with practical visualization. -->
    <!-- Visualization & Content Choices:
        - Report Info: Process States -> Goal: Visualize lifecycle -> Viz/Method: Interactive diagram with HTML/CSS/JS. Interaction: Click a state to highlight it and see its description. Justification: Makes the abstract flow tangible.
        - Report Info: Disk Scheduling Algorithms -> Goal: Compare algorithm efficiency -> Viz/Method: Interactive Chart.js line chart. Interaction: User inputs a request queue, selects an algorithm, and sees the head movement path and total seek time calculated. Justification: Turns a static calculation problem into a dynamic, visual simulation, clarifying performance differences.
        - Report Info: OSI vs TCP/IP Models -> Goal: Compare layered architectures -> Viz/Method: Side-by-side interactive diagram with HTML/CSS/JS. Interaction: Hover over a layer in one model to highlight its equivalent(s) in the other and read a description. Justification: Clearly illustrates the relationship and consolidation of layers between the two models.
        - Report Info: Comparative Tables -> Goal: Easy data lookup -> Viz/Method: HTML tables styled with Tailwind. Interaction: Row hover effects for readability. Justification: Presents dense comparative data in a clean, accessible format.
    -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body {
            font-family: 'Inter', sans-serif;
            transition: background-color 0.3s ease, color 0.3s ease;
        }
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
        .content-section {
            display: none;
        }
        .content-section.active {
            display: block;
        }
        .nav-link.active {
            background-color: #0284c7;
            color: white;
        }
        .sub-nav-link.active {
            background-color: #e0f2fe;
            color: #0c4a6e;
            font-weight: 600;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
            height: 300px;
            max-height: 400px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 350px;
            }
        }
        .process-state {
            transition: all 0.3s ease;
            cursor: pointer;
        }
        .process-state.highlighted {
            transform: scale(1.1);
            box-shadow: 0 0 15px rgba(2, 132, 199, 0.7);
            border-color: #0284c7;
        }
        .model-layer {
            transition: all 0.3s ease;
            cursor: pointer;
        }
        .model-layer:hover {
             background-color: #e0f2fe;
        }

        /* Dark Mode Styles */
        body.dark-mode {
            background-color: #1a202c; /* Dark slate */
            color: #e2e8f0; /* Light gray text */
        }
        .dark-mode header, .dark-mode .bg-white {
            background-color: #2d3748; /* Darker slate for header/cards */
            color: #e2e8f0;
        }
        .dark-mode .shadow-md {
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.3), 0 2px 4px -1px rgba(0, 0, 0, 0.18);
        }
        .dark-mode .text-slate-900 {
            color: #e2e8f0;
        }
        .dark-mode .text-slate-600 {
            color: #a0aec0;
        }
        .dark-mode .text-slate-700 {
            color: #cbd5e0;
        }
        .dark-mode .nav-link {
            background-color: #2d3748;
        }
        .dark-mode .nav-link.active {
            background-color: #0c4a6e; /* Darker blue for active nav */
        }
        .dark-mode .sub-nav-link {
            color: #e2e8f0;
        }
        .dark-mode .sub-nav-link:hover {
            background-color: #4a5568; /* Darker hover for sub-nav */
        }
        .dark-mode .sub-nav-link.active {
            background-color: #0c4a6e;
            color: #e2e8f0;
        }
        .dark-mode .text-sky-800 {
            color: #90cdf4; /* Lighter blue for headers */
        }
        .dark-mode .text-sky-700 {
            color: #63b3ed; /* Lighter blue for strong text */
        }
        .dark-mode .border-slate-300 {
            border-color: #4a5568;
        }
        .dark-mode .bg-slate-100 {
            background-color: #4a5568;
        }
        .dark-mode .bg-sky-50 {
            background-color: #2c5282; /* Darker blue for info boxes */
        }
        .dark-mode .border-sky-500 {
            border-color: #4299e1; /* Lighter blue for borders */
        }
        .dark-mode .bg-slate-100 {
            background-color: #4a5568;
        }
        .dark-mode .hover\:bg-slate-50:hover {
            background-color: #4a5568;
        }
        .dark-mode .model-layer {
            background-color: #4a5568;
        }
        .dark-mode .model-layer:hover {
            background-color: #2c5282;
        }
        .dark-mode footer {
            background-color: #2d3748;
        }
        .dark-mode input, .dark-mode select {
            background-color: #4a5568;
            border-color: #63b3ed;
            color: #e2e8f0;
        }
    </style>
</head>
<body class="bg-stone-50 text-slate-800">

    <div class="min-h-screen flex flex-col">
        <header class="bg-white shadow-md sticky top-0 z-10">
            <div class="container mx-auto px-4 py-4 flex justify-between items-center">
                <div>
                    <h1 class="text-2xl md:text-3xl font-bold text-slate-900">Study Fast As Fcuk: BCA Mid-Sem 3</h1>
                    <p class="text-slate-600 mt-1">Operating Systems (C6) & Computer Networks (C7)</p>
                </div>
                <button id="dark-mode-toggle" class="p-2 rounded-full bg-slate-200 text-slate-800 hover:bg-slate-300 transition-colors duration-300">
                    <span id="dark-mode-icon">ðŸŒ™</span>
                </button>
            </div>
            <nav class="bg-slate-800 text-white">
                <div class="container mx-auto flex justify-center">
                    <button id="btn-os" class="nav-link py-3 px-6 font-semibold transition-colors duration-300 hover:bg-sky-700">Operating Systems</button>
                    <button id="btn-cn" class="nav-link py-3 px-6 font-semibold transition-colors duration-300 hover:bg-sky-700">Computer Networks</button>
                </div>
            </nav>
        </header>

        <div class="flex-grow container mx-auto p-4 md:p-6 lg:p-8">
            <div class="flex flex-col md:flex-row gap-8">
                
                <!-- Sub Navigation -->
                <aside id="os-nav" class="w-full md:w-1/4 lg:w-1/5 content-section">
                    <h2 class="text-xl font-bold mb-4 text-sky-800">C6 Topics</h2>
                    <ul class="space-y-2" data-subject="os"></ul>
                </aside>
                <aside id="cn-nav" class="w-full md:w-1/4 lg:w-1/5 content-section">
                    <h2 class="text-xl font-bold mb-4 text-sky-800">C7 Topics</h2>
                    <ul class="space-y-2" data-subject="cn"></ul>
                </aside>

                <!-- Main Content -->
                <main id="main-content" class="w-full md:w-3/4 lg:w-4/5">
                    <div id="welcome-message" class="bg-white p-8 rounded-lg shadow-md">
                        <h2 class="text-2xl font-bold mb-4 text-slate-900">J A N K A R I !!</h2>
                        <p class="text-slate-700 leading-relaxed">Select a subject above (Operating Systems or Computer Networks) and then choose a topic from the left-hand menu to begin your focused study session. This guide is designed to make complex topics understandable and memorable. Good luck with your exams!</p>
                    </div>
                    <div id="content-display" class="hidden"></div>
                </main>

            </div>
        </div>

        <footer class="bg-slate-800 text-white text-center p-4 mt-8">
            <p>&copy; 2025 Jhatu Exam se bas 2 din phle pdh !. All rights reserved.</p>
        </footer>
    </div>

<script>
const data = {
    os: {
        title: "Operating Systems (C6)",
        topics: {
            types_os: {
                title: "Types of OS",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">Types of Operating Systems</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">Operating systems (OS) serve as the foundational software that manages computer hardware and software resources. Different types of operating systems are engineered to serve specific purposes and environments. Understanding these types is crucial for grasping the evolution and purpose of different OS architectures.</p>
                    <div class="space-y-6">
                        <div>
                            <strong class="text-sky-700">Batch Operating System:</strong> This type of OS processes jobs in batches without direct user interaction during execution. Jobs are pre-scheduled and executed sequentially. This approach minimizes manual intervention and organizes tasks for efficient sequential processing, making it ideal for large organizations with high task volumes, such as payroll processing or large data analysis. Early examples include MS-DOS and DR-DOS.
                        </div>
                        <div>
                            <strong class="text-sky-700">Multiprogramming OS:</strong> A multiprogramming OS allows multiple programs to reside in the main memory concurrently. When one program pauses, for instance, while waiting for an I/O operation to complete, the CPU switches to another program that is ready to execute. This strategy optimizes CPU utilization by preventing it from sitting idle during I/O operations, thereby maximizing its efficiency. It creates the illusion of parallel execution, although, on a single CPU, only one program is truly executing at any given instant. Examples include multi-user systems like Unix, Linux distributions (Solaris, HP-UX, AIX), and Windows XP/Vista/7 & 8.
                        </div>
                        <div>
                            <strong class="text-sky-700">Time-Sharing OS:</strong> A logical extension of multiprogramming, time-sharing operating systems rapidly switch the CPU among multiple jobs (processes), allocating each user or program a small, fixed slice of CPU time, known as a time quantum. This rapid switching creates the illusion that each user has dedicated access to the system, providing quick response times essential for interactive users. However, this interactivity comes at the cost of higher system overhead due to frequent context switching and scheduling activities. Examples include IBM VM/CMS, TSO (Time Sharing Option), and Windows Terminal Services.
                        </div>
                        <div>
                            <strong class="text-sky-700">Real-Time OS (RTOS):</strong> Designed for applications with strict timing constraints, RTOS ensure that tasks are completed within specific, often very short, deadlines. These systems are crucial in environments where precise timing is paramount, such as industrial control, robotics, and medical equipment, prioritizing deterministic behavior over high throughput. RTOS are broadly categorized into:
                            <ul class="list-disc list-inside ml-4 mt-2">
                                <li><strong>Hard Real-Time Systems:</strong> In these systems, missing a deadline is catastrophic and can lead to system failure, as seen in airbag deployment systems or flight control systems.</li>
                                <li><strong>Soft Real-Time Systems:</strong> While missing a deadline is undesirable, it is not catastrophic; performance may degrade but the system continues to function, typical in multimedia streaming or online gaming.</li>
                            </ul>
                        </div>
                        <div>
                            <strong class="text-sky-700">Distributed OS:</strong> A distributed OS manages a collection of independent computers (nodes) networked together, making them appear to users as a single, coherent computing system. This architecture distributes resources like CPU, memory, and storage across multiple machines while providing a unified interface, offering advantages such as fault tolerance, enhanced resource sharing, and scalability. Examples include Amoeba and Mach.
                        </div>
                        <div>
                            <strong class="text-sky-700">Network OS:</strong> This OS runs on a server and facilitates shared access to resources such as files, printers, security, and applications across networked computers. These systems typically manage local area networks (LANs), enabling clients to access shared resources and focusing on network-specific functionalities like user authentication and resource sharing. Windows Server and Novell NetWare are common examples.
                        </div>
                        <div>
                            <strong class="text-sky-700">Mobile OS:</strong> Optimized specifically for mobile devices like smartphones and tablets, mobile operating systems prioritize user interface design, touch input capabilities, and power efficiency. Prominent examples include Apple iOS and Google Android.
                        </div>
                        <div>
                            <strong class="text-sky-700">Embedded OS:</strong> These are specialized operating systems designed to run on dedicated hardware for specific applications, often characterized by limited resources and real-time constraints. They are found in smart appliances, industrial machines, and automotive systems.
                        </div>
                        <div>
                            <strong class="text-sky-700">Multiprocessing OS:</strong> A multiprocessing OS utilizes multiple processing elements, such as multiple CPUs or cores, within a single system to execute tasks simultaneously. This capability significantly increases throughput and computational speed, achieving true parallelism by having multiple CPUs execute different parts of a program or different programs at the same time, unlike multiprogramming which only provides an illusion of parallelism on a single CPU. Examples include Windows Server, Linux/Unix-based distributions (e.g., Red Hat Enterprise Linux), and macOS.
                        </div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">The evolution of operating system functionality has been fundamentally driven by the changing demands of users and advancements in hardware capabilities. The progression from Batch OS, which focused on sequential efficiency for large jobs, to Multiprogramming and Time-Sharing OS, which prioritized CPU utilization and interactivity, directly reflects the evolving needs of computer users. As CPUs became faster and memory became more affordable, the focus shifted from merely processing jobs to providing responsive, multi-user, and concurrent environments. The emergence of Mobile and Embedded OS further illustrates how specific hardware constraints, such as power consumption and physical size, and specialized application domains, like the Internet of Things (IoT) or industrial automation, necessitate the development of tailored OS solutions. This continuous feedback loop between technological advancements and user expectations shapes the landscape of operating systems.</p>
                    <p class="mt-4 text-slate-700 leading-relaxed">The discussion of Time-Sharing OS explicitly highlights "High Overhead" due to the necessity of scheduling and frequent context switching. This exemplifies a fundamental trade-off inherent in OS design: achieving high interactivity and allowing multiple users to share resources, which are benefits of time-sharing, comes at the expense of increased system overhead. Similarly, Hard Real-Time Systems prioritize strict timing determinism, often requiring sacrifices in general-purpose flexibility or maximal resource utilization. There is no single "perfect" operating system type; each is optimized for a particular set of priorities and system goals. Understanding these trade-offs is crucial for comprehending why different OS types are suited for different computational challenges.</p>
                    <h4 class="text-xl font-semibold mt-8 mb-4 text-slate-900">Comparison of OS Types</h4>
                    <div class="overflow-x-auto bg-white p-4 rounded-lg shadow-md">
                        <table class="w-full text-left">
                            <thead class="bg-slate-100">
                                <tr>
                                    <th class="p-3">OS Type</th>
                                    <th class="p-3">Key Characteristic</th>
                                    <th class="p-3">User Interaction</th>
                                    <th class="p-3">Resource Utilization Focus</th>
                                    <th class="p-3">Primary Advantage</th>
                                    <th class="p-3">Primary Disadvantage</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Batch OS</td>
                                    <td class="p-3">Processes jobs in groups without direct user interaction.</td>
                                    <td class="p-3">None (offline)</td>
                                    <td class="p-3">Throughput (sequential)</td>
                                    <td class="p-3">High efficiency for repetitive tasks</td>
                                    <td class="p-3">Lack of interactivity, long turnaround time</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Multiprogramming OS</td>
                                    <td class="p-3">Multiple programs concurrently in memory; CPU switches on I/O wait.</td>
                                    <td class="p-3">Limited</td>
                                    <td class="p-3">CPU utilization</td>
                                    <td class="p-3">Maximizes CPU usage, increased throughput</td>
                                    <td class="p-3">Can still have long wait times for CPU-bound tasks</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Time-Sharing OS</td>
                                    <td class="p-3">CPU time divided into slices; rapid switching among users/programs.</td>
                                    <td class="p-3">Interactive</td>
                                    <td class="p-3">Responsiveness, fairness</td>
                                    <td class="p-3">Good response time, fair resource sharing</td>
                                    <td class="p-3">Higher overhead due to context switching</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Real-Time OS</td>
                                    <td class="p-3">Strict timing constraints; tasks completed within deadlines.</td>
                                    <td class="p-3">Varies</td>
                                    <td class="p-3">Determinism</td>
                                    <td class="p-3">Predictable and timely execution of critical tasks</td>
                                    <td class="p-3">Less flexible, resource-intensive for high determinism</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Distributed OS</td>
                                    <td class="p-3">Manages multiple networked computers as a single system.</td>
                                    <td class="p-3">Interactive</td>
                                    <td class="p-3">Resource sharing, fault tolerance</td>
                                    <td class="p-3">Scalability, reliability, resource sharing</td>
                                    <td class="p-3">High complexity, network overhead</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Network OS</td>
                                    <td class="p-3">Runs on server; facilitates shared access to network resources.</td>
                                    <td class="p-3">Client-server</td>
                                    <td class="p-3">Network resource management</td>
                                    <td class="p-3">Centralized management, shared resources</td>
                                    <td class="p-3">Dependent on network health, security challenges</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Mobile OS</td>
                                    <td class="p-3">Optimized for mobile devices; touch input, power efficiency.</td>
                                    <td class="p-3">Interactive</td>
                                    <td class="p-3">User experience, battery life</td>
                                    <td class="p-3">Portable, user-friendly interface</td>
                                    <td class="p-3">Limited resources, security vulnerabilities</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Embedded OS</td>
                                    <td class="p-3">Specialized for dedicated hardware; specific applications, limited resources.</td>
                                    <td class="p-3">Varies</td>
                                    <td class="p-3">Specific function, efficiency</td>
                                    <td class="p-3">Highly optimized for specific tasks</td>
                                    <td class="p-3">Limited functionality, difficult to update</td>
                                </tr>
                                <tr class="hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Multiprocessing OS</td>
                                    <td class="p-3">Utilizes multiple CPUs/cores for simultaneous task execution.</td>
                                    <td class="p-3">Interactive</td>
                                    <td class="p-3">Parallel processing, throughput</td>
                                    <td class="p-3">True parallel execution, high computational speed</td>
                                    <td class="p-3">Increased complexity in programming and synchronization</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                `
            },
            process_state: {
                title: "Process State",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">Process State Model</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">A process is a program in execution. As a process executes, it changes state. This section provides an interactive diagram to explore the five primary states of a process and the transitions between them. Click on any state to learn more about it.</p>
                    <div class="bg-white p-6 rounded-lg shadow-md">
                        <div id="process-diagram" class="relative flex flex-col items-center space-y-4 font-semibold">
                            <div id="state-new" class="process-state border-2 border-slate-300 bg-slate-100 rounded-lg p-4 w-40 text-center">New</div>
                            <div class="text-2xl">â†“</div>
                            <div id="state-ready" class="process-state border-2 border-slate-300 bg-slate-100 rounded-lg p-4 w-40 text-center">Ready</div>
                            <div class="absolute top-28 left-48 text-2xl transform -rotate-45">â†™</div>
                            <div class="absolute top-28 right-48 text-2xl transform rotate-45">â†˜</div>
                            <div id="state-running" class="process-state border-2 border-slate-300 bg-slate-100 rounded-lg p-4 w-40 text-center">Running</div>
                             <div class="absolute top-52 left-48 text-2xl transform rotate-45">â†–</div>
                            <div class="absolute top-52 right-48 text-2xl transform -rotate-45">â†“</div>
                            <div id="state-waiting" class="process-state border-2 border-slate-300 bg-slate-100 rounded-lg p-4 w-40 text-center">Waiting</div>
                             <div class="absolute top-72 right-48 text-2xl transform rotate-45">â†—</div>
                            <div id="state-terminated" class="process-state border-2 border-slate-300 bg-slate-100 rounded-lg p-4 w-40 text-center">Terminated</div>
                        </div>
                        <div id="process-state-info" class="mt-8 p-4 bg-sky-50 border-l-4 border-sky-500 rounded-r-lg min-h-[100px]">
                            <p class="text-slate-600">Click on a state above to see its description.</p>
                        </div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">The distinct process states and the precise rules governing transitions between them illustrate the operating system's sophisticated control over system resources, particularly the CPU. By meticulously managing these states, the OS ensures that the CPU remains active during I/O operations, a core principle of multiprogramming. It also enables multiple users to share the system responsively in time-sharing environments. This careful orchestration is fundamental to the OS's role in maximizing system throughput and responsiveness.</p>
                    <p class="mt-4 text-slate-700 leading-relaxed">The descriptions of Long-term, Medium-term, and Short-term schedulers explicitly link their roles to the movement of processes between specific states. For instance, the long-term scheduler is responsible for admitting processes from the new state to the ready state, while the short-term scheduler moves processes from the ready state to the running state. This establishes a clear relationship: schedulers are the decision-making components within the OS that enforce and facilitate these state changes, ensuring that processes are admitted, executed, and managed according to defined system policies. Understanding these roles is key to comprehending how the process lifecycle is dynamically driven.</p>
                    <h4 class="text-xl font-semibold mt-8 mb-4 text-slate-900">Process State Transitions</h4>
                    <div class="overflow-x-auto bg-white p-4 rounded-lg shadow-md">
                        <table class="w-full text-left">
                            <thead class="bg-slate-100">
                                <tr>
                                    <th class="p-3">Process State</th>
                                    <th class="p-3">Description</th>
                                    <th class="p-3">Transitions From</th>
                                    <th class="p-3">Transitions To</th>
                                    <th class="p-3">Triggering Event/Scheduler</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">New</td>
                                    <td class="p-3">Program being loaded from secondary memory to primary memory, awaiting admission. At this stage, it typically resides in a job queue, awaiting admission to the system.</td>
                                    <td class="p-3">-</td>
                                    <td class="p-3">Ready</td>
                                    <td class="p-3">Process creation, Long-term Scheduler (admission)</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Ready</td>
                                    <td class="p-3">Loaded in main memory, prepared to execute, waiting for CPU allocation. Processes in the ready state are typically held in a ready queue.</td>
                                    <td class="p-3">New, Running, Waiting/Blocked, Suspended-Ready</td>
                                    <td class="p-3">Running, Suspended-Ready</td>
                                    <td class="p-3">Long-term Scheduler (admission), Preemption, I/O Completion</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Running</td>
                                    <td class="p-3">CPU actively executing process instructions. On a single CPU core, only one process can be in the running state at any given moment.</td>
                                    <td class="p-3">Ready</td>
                                    <td class="p-3">Ready, Waiting/Blocked, Terminated</td>
                                    <td class="p-3">Short-term Scheduler (dispatch)</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Waiting/Blocked</td>
                                    <td class="p-3">Process suspended, awaiting an event (e.g., an I/O operation, resource availability, or user input). While waiting, the process is typically moved to a device-specific queue.</td>
                                    <td class="p-3">Running, Suspended-Wait</td>
                                    <td class="p-3">Ready, Suspended-Wait</td>
                                    <td class="p-3">I/O request, resource unavailability, user input</td>
                                </tr>
                                <tr class="hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Terminated</td>
                                    <td class="p-3">Process completed execution or aborted; resources deallocated.</td>
                                    <td class="p-3">Running</td>
                                    <td class="p-3">-</td>
                                    <td class="p-3">Process completion, explicit termination</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                `
            },
            scheduling: {
                title: "Scheduling Algorithms",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">CPU Scheduling Algorithms</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">CPU scheduling is the process of determining which process in the ready queue is to be allocated the CPU next. The goal is to optimize various performance criteria, such as CPU utilization, throughput, waiting time, and response time. The table below compares common algorithms.</p>
                    <div class="space-y-6">
                        <div>
                            <strong class="text-sky-700">FCFS (First-Come, First-Served):</strong> This is the simplest CPU scheduling algorithm, executing processes in the exact order they arrive in the ready queue. It operates like a queue (First-In, First-Out or FIFO). Once a process gains control of the CPU, it runs to completion without interruption, making it a non-preemptive algorithm. Its advantages include ease of understanding and implementation, and it ensures that no process suffers from starvation, as every process eventually gets served. However, FCFS can lead to high average waiting and turnaround times, particularly if a long process arrives before several short ones, a phenomenon known as the "convoy effect". This makes it less suitable for interactive systems.
                        </div>
                        <div>
                            <strong class="text-sky-700">SJF (Shortest Job First):</strong> This algorithm selects the process with the shortest estimated CPU burst time (the time it needs to complete its next CPU burst) for execution. The underlying idea is to quickly complete short jobs, thereby making the CPU available sooner for other, potentially longer, jobs. SJF can be implemented in two forms:
                            <ul class="list-disc list-inside ml-4 mt-2">
                                <li><strong>Non-preemptive SJF:</strong> Once a process begins execution, it continues until its current CPU burst is complete.</li>
                                <li><strong>Preemptive SJF (Shortest Remaining Time First - SRTF):</strong> If a new process arrives with a CPU burst time shorter than the remaining time of the currently executing process, the current process is preempted and the new, shorter process is executed.</li>
                            </ul>
                            SJF is provably optimal in minimizing the average waiting time and average turnaround time. Its main disadvantage is the practical difficulty of knowing the exact CPU burst time beforehand. Furthermore, it can lead to starvation for longer jobs if a continuous stream of short jobs keeps arriving.
                        </div>
                        <div>
                            <strong class="text-sky-700">Priority Scheduling:</strong> In this algorithm, each process is assigned a priority number, and the CPU is allocated to the process with the highest priority. Priorities can be internally determined (e.g., based on memory requirements or time limits) or externally assigned (e.g., based on the importance of the process). Processes with the same priority are often scheduled using FCFS. This method can be either preemptive or non-preemptive. While high-priority tasks receive quick service, a significant drawback is the potential for indefinite blocking or "starvation" for low-priority processes if high-priority processes continually arrive. This issue can be mitigated through "aging," a technique that gradually increases the priority of processes that have been waiting for a long time.
                        </div>
                        <div>
                            <strong class="text-sky-700">Round Robin (RR):</strong> A preemptive scheduling algorithm specifically designed for time-sharing systems. Each process is given a small, fixed unit of CPU time, known as a time quantum or time slice. If a process does not complete its execution within its allocated time quantum, it is preempted and moved to the end of the ready queue. The CPU then proceeds to the next process in the queue. This mechanism ensures that all processes receive a fair share of the CPU over time, providing good response times for interactive users. The performance of RR heavily depends on the size of the time quantum; a quantum that is too small leads to excessive context switching overhead, reducing efficiency, whereas a quantum that is too large causes RR to behave similarly to FCFS.
                        </div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">The existence of multiple CPU scheduling algorithms, each with distinct advantages and disadvantages, demonstrates that CPU scheduling is not about finding a single "best" solution. Instead, it represents a complex optimization problem where the operating system must balance conflicting objectives, such as maximizing CPU utilization, throughput, and fairness, while simultaneously minimizing waiting time, turnaround time, and response time. The selection of a specific algorithm is contingent upon the system's particular objectives, whether it is a batch processing system prioritizing throughput or an interactive system prioritizing responsiveness.</p>
                    <p class="mt-4 text-slate-700 leading-relaxed">The recurring distinction between "non-preemptive" and "preemptive" algorithms highlights a critical design choice. Preemption, as implemented in algorithms like Round Robin or Shortest Remaining Time First (SRTF), allows the operating system to interrupt a running process and allocate the CPU to another. This capability is directly responsible for achieving responsiveness in interactive and time-sharing systems, as it prevents any single long-running process from monopolizing the CPU. However, this benefit comes with the associated cost of increased overhead due to frequent context switching. Understanding *why* preemption is a necessary feature for modern operating systems and its inherent costs is fundamental.</p>
                    <h4 class="text-xl font-semibold mt-8 mb-4 text-slate-900">Comparison of CPU Scheduling Algorithms</h4>
                    <div class="overflow-x-auto bg-white p-4 rounded-lg shadow-md">
                        <table class="w-full text-left">
                            <thead class="bg-slate-100">
                                <tr>
                                    <th class="p-3">Algorithm</th>
                                    <th class="p-3">Type (Preemptive/Non-preemptive)</th>
                                    <th class="p-3">Core Principle</th>
                                    <th class="p-3">Advantages</th>
                                    <th class="p-3">Disadvantages</th>
                                    <th class="p-3">Best Use Case</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">FCFS</td>
                                    <td class="p-3">Non-preemptive</td>
                                    <td class="p-3">First in, first out</td>
                                    <td class="p-3">Simple to implement, no starvation</td>
                                    <td class="p-3">High average waiting/turnaround time (convoy effect)</td>
                                    <td class="p-3">Batch systems</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">SJF</td>
                                    <td class="p-3">Non-preemptive (SJF) / Preemptive (SRTF)</td>
                                    <td class="p-3">Shortest CPU burst first</td>
                                    <td class="p-3">Minimizes average waiting/turnaround time</td>
                                    <td class="p-3">Requires knowing future burst times, potential starvation for long jobs</td>
                                    <td class="p-3">Batch systems (where burst times are known)</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Priority</td>
                                    <td class="p-3">Preemptive or Non-preemptive</td>
                                    <td class="p-3">Highest priority process first</td>
                                    <td class="p-3">High-priority tasks get quick service</td>
                                    <td class="p-3">Starvation for low-priority processes, aging needed</td>
                                    <td class="p-3">Real-time systems, batch systems with critical jobs</td>
                                </tr>
                                <tr class="hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Round Robin</td>
                                    <td class="p-3">Preemptive</td>
                                    <td class="p-3">Each process gets a time slice</td>
                                    <td class="p-3">Fair CPU allocation, good response time</td>
                                    <td class="p-3">High context switching overhead if quantum is too small</td>
                                    <td class="p-3">Time-sharing systems, interactive systems</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                `
            },
            paging_segmentation: {
                title: "Paging & Segmentation",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">Paging vs. Segmentation</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">Paging and segmentation are two primary memory management techniques that allow a process's physical address space to be non-contiguous. They address the problem of fitting processes of varying sizes into memory, but they do so in different ways and have different trade-offs, particularly concerning fragmentation.</p>
                    <div class="space-y-6">
                        <div>
                            <strong class="text-sky-700">Segmentation:</strong> Segmentation is a memory management technique that divides a program's logical address space into variable-sized units called "segments." Each segment corresponds to a logical unit of the program, such as code, data, or stack, and these segments can vary in size. A memory address in a segmented system consists of a <code>segment ID</code> and an <code>offset</code> within that segment. The Memory Management Unit (MMU), a hardware component, is responsible for translating this logical address into a physical address and performing necessary access checks.
                            <h4 class="text-lg font-semibold mt-2 mb-1 text-sky-800">Advantages of Segmentation:</h4>
                            <ul class="list-disc list-inside ml-4 text-slate-600">
                                <li>Provides a logical view of memory that aligns with the programmer's view of the program, making it easier to manage and debug.</li>
                                <li>Reduces internal fragmentation, as segments are variable-sized and can be allocated to fit the exact size of logical units, minimizing unused space within allocated blocks.</li>
                                <li>Enhances protection and sharing; different segments can have distinct access permissions (e.g., read-only code, read-write data), and shared segments, such as libraries, can be easily implemented by multiple processes pointing to the same physical segment.</li>
                                <li>Relocating segments in physical memory is also simpler.</li>
                            </ul>
                            <h4 class="text-lg font-semibold mt-2 mb-1 text-sky-800">Disadvantages of Segmentation:</h4>
                            <ul class="list-disc list-inside ml-4 text-slate-600">
                                <li>The primary drawback is external fragmentation. As segments are loaded and unloaded, variable-sized free holes appear in physical memory. Even if sufficient total free memory exists, it might not be contiguous enough to accommodate a new, larger segment, leading to wasted memory.</li>
                                <li>To mitigate external fragmentation, memory compaction (rearranging segments to consolidate free space) becomes necessary, which is a computationally expensive process.</li>
                                <li>Requires more complex MMU hardware for address translation and size checks.</li>
                            </ul>
                        </div>
                        <div>
                            <strong class="text-sky-700">Paging:</strong> Paging is a memory management scheme that divides both physical memory and a program's logical address space into fixed-size blocks. Physical memory is divided into "frames," and logical memory (the program) is divided into "pages." The size of pages is typically a power of two. The operating system maintains a <code>page table</code> for each process, which maps logical pages to physical frames. When the CPU generates a virtual address, the MMU uses the page table to translate it into a physical address in RAM. A key characteristic of paging is that a process's pages can be scattered non-contiguously throughout physical memory.
                            <h4 class="text-lg font-semibold mt-2 mb-1 text-sky-800">Advantages of Paging:</h4>
                            <ul class="list-disc list-inside ml-4 text-slate-600">
                                <li>Effectively eliminates external fragmentation because all frames and pages are of fixed size, allowing any free frame to be used for any page.</li>
                                <li>Non-contiguous allocation of a process's pages into physical memory locations makes memory allocation highly flexible.</li>
                                <li>Transparent to the programmer, meaning they do not need to concern themselves with memory allocation or fragmentation, as these aspects are handled by the OS and hardware.</li>
                                <li>Generally considered easier to implement for memory allocation compared to segmentation.</li>
                            </ul>
                            <h4 class="text-lg font-semibold mt-2 mb-1 text-sky-800">Disadvantages of Paging:</h4>
                            <ul class="list-disc list-inside ml-4 text-slate-600">
                                <li>Can lead to internal fragmentation, where a process might not fully utilize its last allocated page, resulting in a small amount of unused space within that page.</li>
                                <li>Overhead associated with page tables, which can consume a significant amount of memory, especially for large address spaces. Multi-level page tables can reduce this overhead but introduce additional complexity and potentially increase memory access time.</li>
                                <li>Typically two memory accesses are required for each data access (one for the page table entry and one for the actual data), though a Translation Lookaside Buffer (TLB) helps to speed up this process.</li>
                            </ul>
                        </div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">The detailed descriptions of both segmentation and paging underscore that memory fragmentation is a persistent and fundamental challenge in operating system design. While paging effectively eliminates external fragmentation, it introduces internal fragmentation. Conversely, segmentation minimizes internal fragmentation but is susceptible to external fragmentation. This highlights a continuous trade-off in memory management techniques: designers often mitigate one type of fragmentation at the expense of another or by introducing additional overheads, such as page tables or the need for compaction. This demonstrates that there is no single perfect solution, but rather a set of compromises tailored to specific system requirements.</p>
                    <p class="mt-4 text-slate-700 leading-relaxed">The role of the Memory Management Unit (MMU) is central to both segmentation and paging, as it is responsible for address translation in both schemes. Furthermore, segments can be used to implement virtual memory. This indicates that paging and segmentation are not merely isolated memory division techniques but are foundational components of virtual memory systems. They enable processes to utilize a logical address space that can be larger than the physical RAM, provide essential memory protection between different processes, and facilitate efficient memory sharing. The MMU is the critical hardware component that makes this powerful abstraction possible, allowing for a more flexible and robust memory environment.</p>
                    <h4 class="text-xl font-semibold mt-8 mb-4 text-slate-900">Comparison of Paging and Segmentation</h4>
                    <div class="overflow-x-auto bg-white p-4 rounded-lg shadow-md">
                        <table class="w-full text-left">
                            <thead class="bg-slate-100">
                                <tr>
                                    <th class="p-3">Feature</th>
                                    <th class="p-3">Paging</th>
                                    <th class="p-3">Segmentation</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Unit Size</td>
                                    <td class="p-3">Fixed-size blocks (pages/frames)</td>
                                    <td class="p-3">Variable-sized blocks (segments)</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Logical View</td>
                                    <td class="p-3">Linear address space, transparent to programmer</td>
                                    <td class="p-3">Logical view of program (code, data, stack), meaningful units</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Fragmentation Type</td>
                                    <td class="p-3">Internal fragmentation (small unused space within pages)</td>
                                    <td class="p-3">External fragmentation (unused holes between segments)</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Address Space</td>
                                    <td class="p-3">Flat, single linear address space for program</td>
                                    <td class="p-3">Collection of independent address spaces (segments)</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Physical Memory Allocation</td>
                                    <td class="p-3">Non-contiguous (pages can be anywhere)</td>
                                    <td class="p-3">Contiguous (each segment needs contiguous space)</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Programmer Transparency</td>
                                    <td class="p-3">Highly transparent; OS handles memory management</td>
                                    <td class="p-3">Less transparent; programmer may be aware of segments</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Complexity</td>
                                    <td class="p-3">Simpler to implement in practice for memory allocation</td>
                                    <td class="p-3">More complex MMU hardware for address translation and size checks</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Overhead</td>
                                    <td class="p-3">Page table overhead (can be large), potential for multi-level tables</td>
                                    <td class="p-3">Compaction overhead (to reduce external fragmentation)</td>
                                </tr>
                                <tr class="hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Primary Purpose</td>
                                    <td class="p-3">Eliminate external fragmentation, implement virtual memory</td>
                                    <td class="p-3">Logical program division, protection, sharing</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                `
            },
            demand_paging: {
                title: "Demand Paging",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">Demand Paging & Page Replacement</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">Demand paging is a technique used in virtual memory systems where pages are loaded into main memory only when they are actually needed (demanded) by the CPU, rather than loading an entire program or process at once. This approach leverages the principle of locality of reference, assuming that a process typically requires only a small portion of its code and data at any given time. This allows processes to run even if they are only partially resident in main memory, significantly maximizing the number of processes that can be active concurrently.</p>
                    <div class="space-y-6">
                        <div>
                            <strong class="text-sky-700">Page Fault:</strong> A page fault is an event that occurs when a program attempts to access a memory page that is currently not loaded into physical RAM. When a page fault occurs, the CPU triggers an interrupt, transferring control to the operating system. The OS then identifies the required page, finds a free frame in main memory (or selects an existing page to replace if no free frames are available), loads the required page from secondary storage (disk) into that frame, updates the page table to reflect the new mapping, and finally restarts the interrupted instruction.
                        </div>
                        <div>
                            <strong class="text-sky-700">Page Replacement Algorithms:</strong> When a page fault occurs and all available memory frames are already occupied, the operating system must decide which existing page in memory to remove (replace) to make space for the newly demanded page. The primary objective of these algorithms is to minimize future page faults.
                            <ul class="list-disc list-inside ml-4 mt-2">
                                <li><strong>FIFO (First-In, First-Out):</strong> This algorithm replaces the page that has been in memory for the longest duration, irrespective of how frequently or recently it has been used. It treats memory frames as a queue, where the oldest page is at the front and is the first to be replaced. While simple to implement, FIFO can be inefficient, as it might replace a frequently used page if it was loaded early. It also suffers from Belady's Anomaly, a counter-intuitive phenomenon where increasing the number of available memory frames can sometimes lead to an increase in page faults.</li>
                                <li><strong>LRU (Least Recently Used):</strong> This algorithm replaces the page that has not been used for the longest period of time; that is, the page whose last access time is the furthest in the past. LRU generally performs well because it effectively leverages the principle of temporal locality, which suggests that pages recently used are likely to be used again soon. This often results in fewer page faults compared to FIFO. However, LRU is complex to implement in practice, as it requires tracking the exact usage time or order of all pages in memory, often necessitating mechanisms like timestamps or a stack, which can introduce significant overhead.</li>
                                <li><strong>Optimal Page Replacement (OPT/MIN):</strong> This algorithm replaces the page that will not be used for the longest period of time in the future. Theoretically, this algorithm yields the lowest possible number of page faults for a given page reference string and number of frames, making it the "perfect" algorithm. However, it is impossible to implement in a real operating system because it requires foreknowledge of future page references. Consequently, it is primarily used as a benchmark to evaluate the efficiency and upper bound performance of other, practically implementable page replacement algorithms.</li>
                            </ul>
                        </div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">Demand paging is the core mechanism that makes virtual memory practical. By loading pages only when they are explicitly required, it enables systems to run programs that are much larger than the available physical RAM. The page fault mechanism is the direct trigger for this on-demand loading, ensuring that necessary data is brought into memory dynamically. This significantly enhances the system's multiprogramming capabilities and overall efficiency by making more effective use of limited physical memory.</p>
                    <p class="mt-4 text-slate-700 leading-relaxed">The clear distinction between the Optimal Page Replacement algorithm, which is "perfect" but "not possible in practice," and algorithms like FIFO and LRU, highlights a critical design principle in computer science: theoretical optimality often comes at the expense of practical implementability, especially when future knowledge is a prerequisite. Real-world algorithms are thus compromises, balancing performance with the feasibility of implementation and the overhead they introduce. This underscores the continuous need for trade-offs in system design.</p>
                    <h4 class="text-xl font-semibold mt-8 mb-4 text-slate-900">Comparison of Page Replacement Algorithms</h4>
                    <div class="overflow-x-auto bg-white p-4 rounded-lg shadow-md">
                        <table class="w-full text-left">
                            <thead class="bg-slate-100">
                                <tr>
                                    <th class="p-3">Algorithm</th>
                                    <th class="p-3">Core Principle</th>
                                    <th class="p-3">Advantages</th>
                                    <th class="p-3">Disadvantages</th>
                                    <th class="p-3">Implementability/Real-world Use</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">FIFO (First-In, First-Out)</td>
                                    <td class="p-3">Replaces the oldest page in memory.</td>
                                    <td class="p-3">Simple to implement.</td>
                                    <td class="p-3">Can be inefficient; may replace frequently used pages. Suffers from Belady's Anomaly.</td>
                                    <td class="p-3">Easy to implement, but rarely used in practice for performance reasons.</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">LRU (Least Recently Used)</td>
                                    <td class="p-3">Replaces the page not used for the longest time.</td>
                                    <td class="p-3">Generally performs well, fewer page faults than FIFO. Leverages temporal locality.</td>
                                    <td class="p-3">Complex to implement (requires tracking usage time/order). Significant overhead.</td>
                                    <td class="p-3">Widely used or approximated in real systems due to good performance.</td>
                                </tr>
                                <tr class="hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Optimal (OPT/MIN)</td>
                                    <td class="p-3">Replaces the page that will not be used for the longest time in the future.</td>
                                    <td class="p-3">Yields the lowest possible page faults (perfect).</td>
                                    <td class="p-3">Impossible to implement (requires future knowledge).</td>
                                    <td class="p-3">Used as a benchmark for evaluating other algorithms.</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                `
            },
            disk_scheduling: {
                title: "Disk Scheduling",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">Interactive Disk Scheduling Simulator</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">Disk scheduling algorithms optimize disk I/O performance by deciding the order to service read/write requests, aiming to minimize seek time. Use the simulator below to see how different algorithms handle the same set of requests. Enter a comma-separated list of cylinder requests and see the results.</p>
                    <div class="bg-white p-6 rounded-lg shadow-md">
                        <div class="grid grid-cols-1 md:grid-cols-2 gap-4 mb-4">
                            <div>
                                <label for="requests" class="block font-semibold mb-1">Request Queue (0-199):</label>
                                <input type="text" id="requests" class="w-full p-2 border rounded" value="98,183,37,122,14,124,65,67">
                            </div>
                            <div>
                                <label for="startPos" class="block font-semibold mb-1">Start Position:</label>
                                <input type="number" id="startPos" class="w-full p-2 border rounded" value="53">
                            </div>
                            <div>
                                <label for="algorithm" class="block font-semibold mb-1">Algorithm:</label>
                                <select id="algorithm" class="w-full p-2 border rounded">
                                    <option value="fcfs">FCFS</option>
                                    <option value="sstf">SSTF</option>
                                    <option value="scan">SCAN</option>
                                    <option value="c-scan">C-SCAN</option>
                                    <option value="look">LOOK</option>
                                    <option value="c-look">C-LOOK</option>
                                </select>
                            </div>
                            <div class="flex items-end">
                                <button id="run-sim" class="w-full bg-sky-600 text-white p-2 rounded hover:bg-sky-700 transition-colors">Run Simulation</button>
                            </div>
                        </div>
                        <div class="chart-container">
                            <canvas id="disk-chart"></canvas>
                        </div>
                        <div id="sim-results" class="mt-4 text-center font-semibold text-lg"></div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">The array of disk scheduling algorithms (FCFS, SSTF, SCAN, LOOK, and their circular variants) illustrates that optimizing disk I/O is a multifaceted challenge. FCFS, while simple and fair, is often inefficient in terms of total head movement. SSTF prioritizes efficiency by minimizing seek time but can compromise fairness by potentially leading to starvation for distant requests. Algorithms like SCAN and LOOK, along with their circular counterparts, attempt to strike a balance, aiming for good throughput while also ensuring that requests are serviced fairly and with predictable response times. The "scheduling problem" in the syllabus refers to this complex optimization act, where various performance metrics must be considered.</p>
                    <p class="mt-4 text-slate-700 leading-relaxed">Algorithms such as SSTF, SCAN, and LOOK implicitly leverage the principle of "locality of reference" in disk I/O. This principle suggests that requests for data physically close to each other on the disk tend to occur in clusters. By prioritizing requests near the current head position (SSTF) or by sweeping across the disk in a structured manner (SCAN/LOOK), these algorithms significantly reduce the expensive mechanical movement of the disk head. This approach is analogous to how the Least Recently Used (LRU) page replacement algorithm benefits from temporal locality in memory management, demonstrating a common underlying theme in system optimization.</p>
                    <h4 class="text-xl font-semibold mt-8 mb-4 text-slate-900">Comparison of Disk Scheduling Algorithms</h4>
                    <div class="overflow-x-auto bg-white p-4 rounded-lg shadow-md">
                        <table class="w-full text-left">
                            <thead class="bg-slate-100">
                                <tr>
                                    <th class="p-3">Algorithm</th>
                                    <th class="p-3">Core Principle</th>
                                    <th class="p-3">Disk Arm Movement Pattern</th>
                                    <th class="p-3">Advantages</th>
                                    <th class="p-3">Disadvantages</th>
                                    <th class="p-3">Best Use Case</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">FCFS</td>
                                    <td class="p-3">Service requests in order of arrival.</td>
                                    <td class="p-3">Unpredictable, follows request order.</td>
                                    <td class="p-3">Simple, fair, no starvation.</td>
                                    <td class="p-3">High total head movement, poor performance.</td>
                                    <td class="p-3">Simple, low-load systems.</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">SSTF</td>
                                    <td class="p-3">Service request closest to current head position.</td>
                                    <td class="p-3">Moves to nearest request.</td>
                                    <td class="p-3">Minimizes total head movement, high throughput.</td>
                                    <td class="p-3">Potential for starvation of distant requests.</td>
                                    <td class="p-3">Batch systems where throughput is critical.</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">SCAN</td>
                                    <td class="p-3">Move in one direction, service requests, then reverse.</td>
                                    <td class="p-3">Sweeps from one end to the other, then back.</td>
                                    <td class="p-3">Low variance in response time, good throughput, low starvation risk.</td>
                                    <td class="p-3">Requests at ends of sweep may wait longer.</td>
                                    <td class="p-3">Systems with heavy load, provides predictable service.</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">C-SCAN</td>
                                    <td class="p-3">Move in one direction, service requests, then jump back to start without service.</td>
                                    <td class="p-3">Sweeps in one direction, then rapid return.</td>
                                    <td class="p-3">More uniform waiting time, better performance than SCAN.</td>
                                    <td class="p-3">Still traverses entire disk range even if no requests.</td>
                                    <td class="p-3">Systems requiring uniform waiting times.</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">LOOK</td>
                                    <td class="p-3">Like SCAN, but only moves to the furthest request in current direction.</td>
                                    <td class="p-3">Sweeps only between min/max requests in current direction.</td>
                                    <td class="p-3">Saves time by avoiding unnecessary full-disk traversal, efficient.</td>
                                    <td class="p-3">Still has some variance in waiting time.</td>
                                    <td class="p-3">General-purpose systems, more efficient than SCAN.</td>
                                </tr>
                                <tr class="hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">C-LOOK</td>
                                    <td class="p-3">Like C-SCAN, but only moves to the furthest request in current direction, then jumps to first in opposite.</td>
                                    <td class="p-3">Sweeps in one direction, then rapid jump to start of opposite requests.</td>
                                    <td class="p-3">Best performance, avoids starvation, low variance in response time.</td>
                                    <td class="p-3">More complex to implement.</td>
                                    <td class="p-3">High-performance systems, real-time applications.</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                `
            },
            free_swap_space: {
                title: "Free & Swap Space",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">Free Space and Swap Space Management</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">Efficiently managing disk space is a critical OS function. This involves tracking available blocks (free space) and using a portion of the disk as an extension of RAM (swap space).</p>
                    <div class="space-y-6">
                        <div>
                            <h4 class="text-xl font-semibold mb-2 text-sky-800">Free Space Management</h4>
                            <p class="mb-2 text-slate-700 leading-relaxed">Purpose: In an operating system, free space management is essential for the efficient utilization of disk space. It involves meticulously keeping track of which disk blocks are free (available for new data) and which are currently allocated to files. This capability enables the OS to allocate contiguous or non-contiguous space for new files as needed and to efficiently reclaim and reuse space from deleted files, preventing data loss and maximizing storage capacity.</p>
                            <p class="mb-2 text-slate-700 leading-relaxed">Common techniques:</p>
                            <ul class="list-disc list-inside ml-4 text-slate-600">
                                <li><strong>Bitmap (Bit Vector):</strong> This is a widely used and straightforward method. A bit vector, also known as a bitmap, is an array of bits where each bit corresponds to a specific disk block. If a bit is set to '1', it indicates that the corresponding disk block is free; if it's '0', the block is occupied (or vice-versa, depending on the system's convention).
                                    <ul class="list-circle list-inside ml-8 text-slate-600">
                                        <li>Advantages: Simple to implement and efficient for finding contiguous blocks of free space, which is often desirable for large files.</li>
                                        <li>Disadvantages: The bitmap itself can consume a significant amount of memory for very large disks, and searching for a specific number of free blocks can still be time-consuming.</li>
                                    </ul>
                                </li>
                                <li><strong>Linked List:</strong> In this approach, all free blocks on the disk are linked together in a linked list. Each free block contains a pointer to the next free block, and the last pointer in the list typically points to null, indicating the end of the list.
                                    <ul class="list-circle list-inside ml-8 text-slate-600">
                                        <li>Advantages: Simple to implement and requires minimal extra space if pointers are stored within the free blocks themselves.</li>
                                        <li>Disadvantages: Traversing the list to find a free block can be slow, as it often requires reading each disk block one by one, leading to significant I/O time. It is also inefficient for finding contiguous blocks.</li>
                                    </ul>
                                </li>
                                <li><strong>Grouping:</strong> This technique is considered a modification of the linked list approach. Instead of each free block pointing to just the next one, the first free block in a group contains the addresses of 'n' other free blocks. The last of these 'n' blocks then contains the addresses of the next 'n' free blocks, and so on.
                                    <ul class="list-circle list-inside ml-8 text-slate-600">
                                        <li>Advantages: Reduces the number of disk I/O operations required to find multiple free blocks compared to a simple linked list. It can separate empty and occupied blocks more effectively.</li>
                                        <li>Disadvantages: More complex to manage than a simple linked list.</li>
                                    </ul>
                                </li>
                                <li><strong>Counting:</strong> This method is particularly useful when multiple files are created and deleted simultaneously, leading to contiguous runs of free blocks. Instead of tracking each free block individually, the free space list contains entries that consist of two parameters: the address of the first free disk block (a pointer) and a count 'n' representing the number of contiguous free blocks starting from that address.
                                    <ul class="list-circle list-inside ml-8 text-slate-600">
                                        <li>Advantages: Very efficient for managing large contiguous free areas. Reduces the size of the free space list significantly when many contiguous blocks are freed or allocated.</li>
                                        <li>Disadvantages: Less efficient when free blocks are highly fragmented and not contiguous.</li>
                                    </ul>
                                </li>
                            </ul>
                            <p class="mt-4 text-slate-700 leading-relaxed">The necessity of free space management highlights a fundamental challenge in disk utilization: the dynamic nature of file creation and deletion inevitably leads to fragmentation of available space. Without robust management techniques, the disk would quickly become unusable, even if a large amount of total free space exists. The various techniques represent different strategies to balance the efficiency of finding free space with the overhead of maintaining the free space information itself. For instance, a bitmap is excellent for finding contiguous blocks but can be large, while counting is efficient for contiguous runs but less so for scattered free blocks. This demonstrates a continuous effort to optimize storage allocation and deallocation.</p>
                        </div>
                        <div>
                            <h4 class="text-xl font-semibold mb-2 text-sky-800">Swap Space Management</h4>
                            <p class="mb-2 text-slate-700 leading-relaxed">Purpose: Swap space, often implemented as a dedicated disk partition or a file, serves as an extension of a computer's physical RAM (main memory). Its primary purpose is to expand the amount of usable memory beyond what the physical hardware actually holds. When the physical RAM is fully utilized and additional processes or applications require memory, the operating system initiates memory swapping. This process temporarily moves inactive or lower-priority processes or portions of their memory (pages) from physical RAM to the swap space on the hard disk. This frees up physical memory for active processes, enabling the seamless operation of more applications and ensuring system stability.</p>
                            <p class="mb-2 text-slate-700 leading-relaxed">Techniques and Mechanisms:</p>
                            <ul class="list-disc list-inside ml-4 text-slate-600">
                                <li><strong>Virtual Memory Extension:</strong> Swap space forms a crucial part of the virtual memory system. The operating system maps the physical memory space to the swap space, allowing processes to use a virtual address space that can exceed the physical RAM. This means a large process can run even if only parts of it are currently in physical memory.</li>
                                <li><strong>Page-Out/Page-In (Roll In/Roll Out):</strong> When physical memory is low, the OS identifies "old" or inactive pages and "pages them out" to swap space. If these pages are later needed, they are "paged in" (loaded back) from swap space into physical RAM. This process is also known as "roll in/roll out".</li>
                                <li><strong>Swap File/Partition:</strong> Swap space can be implemented as a dedicated partition on the hard disk or as a special file within an existing file system.</li>
                                <li><strong>Swap Management Data Structures:</strong> The OS maintains data structures, such as a <code>swap_map</code> (in Linux, for example), which is an array with entries for each page-sized slot in the swap area. Each entry typically stores a reference count, indicating how many users (e.g., processes, page table entries) are referencing that swap slot. This helps the OS track allocated and free swap slots.</li>
                                <li><strong>Priority and Clustering:</strong> Swap areas can be assigned priorities, influencing how likely they are to be used. Some systems attempt to allocate pages in cluster blocks within the swap area to increase the chance that related pages are stored together, potentially improving I/O performance.</li>
                            </ul>
                            <p class="mt-4 text-slate-700 leading-relaxed">The existence of swap space primarily addresses two fundamental aspects of memory management. First, it directly expands the perceived amount of available memory, allowing larger processes to execute and more processes to run concurrently than physical RAM alone would permit. Second, it provides a mechanism to offload infrequently used memory pages. Many pages referenced early in a process's lifecycle, such as those used for initialization, may not be needed again. Swapping these "cold" pages out to disk frees up valuable physical RAM for actively used data or for disk buffers, thereby improving overall system responsiveness and efficiency, even in systems with ample RAM. This demonstrates how swap space contributes to both memory capacity and memory optimization.</p>
                        </div>
                    </div>
                `
            }
        }
    },
    cn: {
        title: "Computer Networks (C7)",
        topics: {
            osi_model: {
                title: "OSI Model",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">OSI vs. TCP/IP Model Comparator</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">The OSI (Open Systems Interconnection) model is a conceptual framework created by the International Organization for Standardization (ISO) to standardize how different network systems communicate. It divides network communication into seven distinct layers, each with specific functions and protocols. This layered approach simplifies the design, implementation, and troubleshooting of network protocols by breaking down complex processes into manageable sub-tasks. Hover over a layer in either model to see its function and how it maps to the other model.</p>
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-6 items-start">
                        <!-- OSI Model -->
                        <div class="text-center">
                            <h4 class="text-xl font-semibold mb-3">OSI Model (7 Layers)</h4>
                            <div id="osi-layers" class="space-y-1">
                                <div class="model-layer p-3 border rounded-md bg-white" data-layer="app" data-map="app">7. Application</div>
                                <div class="model-layer p-3 border rounded-md bg-white" data-layer="pres" data-map="app">6. Presentation</div>
                                <div class="model-layer p-3 border rounded-md bg-white" data-layer="sess" data-map="app">5. Session</div>
                                <div class="model-layer p-3 border rounded-md bg-white" data-layer="trans" data-map="trans">4. Transport</div>
                                <div class="model-layer p-3 border rounded-md bg-white" data-layer="net" data-map="net">3. Network</div>
                                <div class="model-layer p-3 border rounded-md bg-white" data-layer="data" data-map="link">2. Data Link</div>
                                <div class="model-layer p-3 border rounded-md bg-white" data-layer="phys" data-map="link">1. Physical</div>
                            </div>
                        </div>
                        <!-- TCP/IP Model -->
                        <div class="text-center">
                            <h4 class="text-xl font-semibold mb-3">TCP/IP Model (4 Layers)</h4>
                            <div id="tcpip-layers" class="space-y-1">
                                <div class="model-layer p-3 border rounded-md bg-white h-[140px] flex items-center justify-center" data-layer="app" data-map="app,pres,sess">Application</div>
                                <div class="model-layer p-3 border rounded-md bg-white" data-layer="trans" data-map="trans">Transport</div>
                                <div class="model-layer p-3 border rounded-md bg-white" data-layer="net" data-map="net">Internet</div>
                                <div class="model-layer p-3 border rounded-md bg-white h-[92px] flex items-center justify-center" data-layer="link" data-map="data,phys">Network Access</div>
                            </div>
                        </div>
                        <!-- Info Box -->
                        <div id="model-info" class="bg-sky-50 p-4 rounded-lg border-l-4 border-sky-500 min-h-[300px]">
                            <p class="text-slate-600">Hover over a layer to learn more.</p>
                        </div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">The OSI model's layered architecture is instrumental in standardizing networking concepts and practices. This modular design allows each layer to operate independently, providing services to the layer above and utilizing services from the layer below. This separation of concerns simplifies the design and implementation of network protocols, making networks more manageable and interoperable. The concept of PDUs (Protocol Data Units) at each layer, where data is encapsulated with layer-specific headers, is a direct consequence of this modularity, enabling distinct functionalities at each stage of data transmission.</p>
                    <h4 class="text-xl font-semibold mt-8 mb-4 text-slate-900">TCP/IP Model Overview</h4>
                    <p class="mb-6 text-slate-700 leading-relaxed">The TCP/IP model, developed by the Defense Advanced Research Projects Agency (DARPA) in the 1970s, is an open, vendor-neutral, public networking model that describes general guidelines for designing and implementing computer protocols. It is a more streamlined model compared to OSI, consisting of four layers.</p>
                    <div class="space-y-4">
                        <div><strong class="text-sky-700">Network Access Layer:</strong> This layer combines the functionalities of the OSI model's Physical and Data Link layers. It defines the protocols and hardware required to deliver data across a physical network, handling physical addressing, framing, and access to the network medium.</div>
                        <div><strong class="text-sky-700">Internet Layer:</strong> Equivalent to the OSI's Network Layer, this layer defines protocols for logically transmitting packets over the network. It handles device addressing (IP addresses), routing, and path determination.</div>
                        <div><strong class="text-sky-700">Transport Layer:</strong> Similar to the OSI's Transport Layer, this layer defines protocols for setting the level of transmission service for applications. It is responsible for the reliable transmission of data and error-free delivery of packets, using protocols like TCP (connection-oriented) and UDP (connectionless).</div>
                        <div><strong class="text-sky-700">Application Layer:</strong> This layer merges the functionalities of the OSI's Application, Presentation, and Session layers. It defines protocols for node-to-node application communication and provides services directly to application software running on a computer, including protocols for web browsing (HTTP), file transfer (FTP), and email (SMTP).</div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">The streamlined structure of the TCP/IP model, with fewer layers compared to the OSI model, reflects a design philosophy prioritizing practical implementation over theoretical comprehensiveness. While the OSI model offers a highly detailed and abstract framework for understanding network functions, the TCP/IP model consolidates these functions into fewer layers, making it more adaptable and efficient for real-world network operations, particularly the Internet. This difference in design approach highlights a fundamental tension in engineering between creating an exhaustive theoretical model and developing a pragmatic, deployable solution.</p>
                    <h4 class="text-xl font-semibold mt-8 mb-4 text-slate-900">Comparison of OSI Model and TCP/IP Model</h4>
                    <div class="overflow-x-auto bg-white p-4 rounded-lg shadow-md">
                        <table class="w-full text-left">
                            <thead class="bg-slate-100">
                                <tr>
                                    <th class="p-3">Feature</th>
                                    <th class="p-3">OSI Model</th>
                                    <th class="p-3">TCP/IP Model</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Number of Layers</td>
                                    <td class="p-3">7 Layers</td>
                                    <td class="p-3">4 Layers</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Layers</td>
                                    <td class="p-3">Application, Presentation, Session, Transport, Network, Data Link, Physical</td>
                                    <td class="p-3">Application, Transport, Internet, Network Access</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Development</td>
                                    <td class="p-3">Theoretical reference model, developed by ISO</td>
                                    <td class="p-3">Practical implementation model, developed by DARPA</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Protocol Dependence</td>
                                    <td class="p-3">Protocols developed after the model (less specific)</td>
                                    <td class="p-3">Model developed around existing protocols (more specific)</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Reliability</td>
                                    <td class="p-3">Connection-oriented and connectionless communication in Transport layer</td>
                                    <td class="p-3">Primarily connectionless in Network layer, connection-oriented (TCP) in Transport layer</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Interoperability</td>
                                    <td class="p-3">Defines clear interfaces for interoperability</td>
                                    <td class="p-3">Less strict, but widely adopted for interoperability</td>
                                </tr>
                                <tr class="hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Usage</td>
                                    <td class="p-3">Primarily for conceptual understanding and troubleshooting</td>
                                    <td class="p-3">Basis for the Internet, widely used in practice</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                `
            },
            network_devices: {
                title: "Network Devices",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">Network Devices</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">Network devices are physical components that enable hardware on a computer network to communicate and interact with each other. They manage and direct data flow, boost signals, and link different networks, ensuring efficient communication.</p>
                    <div class="space-y-6">
                        <div>
                            <strong class="text-sky-700">Repeater:</strong> A repeater operates at the Physical Layer of the OSI model. Its main function is to regenerate (amplify) a signal over the same network before it becomes too weak or corrupted, thereby extending the maximum distance over which the signal can be transmitted. It is typically a 2-port device.
                        </div>
                        <div>
                            <strong class="text-sky-700">Hub:</strong> A hub is essentially a multi-port repeater, connecting multiple wires from different network branches, often used in a star topology. Hubs operate at the Physical Layer. They cannot filter data; instead, they broadcast incoming data packets to all connected devices, meaning all hosts connected through a hub share a single collision domain.
                        </div>
                        <div>
                            <strong class="text-sky-700">Bridge:</strong> A bridge operates at the Data Link Layer (Layer 2). It functions as a repeater but with the added capability of filtering content by reading the MAC addresses of source and destination devices. Bridges are used to interconnect two LANs that operate on the same protocol, dividing the collision domain but keeping the broadcast domain the same. Modern multi-port bridges are often referred to as Layer 2 switches.
                        </div>
                        <div>
                            <strong class="text-sky-700">Switch:</strong> A switch is a more advanced network device, essentially a multi-port bridge with internal buffering to enhance efficiency and performance. Operating at the Data Link Layer, a switch performs error checking before forwarding data, selectively sending good packets only to the correct destination port. This significantly reduces network traffic and divides the collision domain for connected hosts, though the broadcast domain remains unified.
                        </div>
                        <div>
                            <strong class="text-sky-700">Router:</strong> A router operates at the Network Layer (Layer 3). Its primary function is to connect different networks (e.g., LANs to WANs) and forward data packets between them based on logical addresses (IP addresses). Routers determine the best path for data delivery across interconnected networks. They divide both collision and broadcast domains.
                        </div>
                        <div>
                            <strong class="text-sky-700">Gateway:</strong> A gateway acts as a passage to connect two networks that may operate on entirely different networking models or protocols. They function as protocol converters, taking data from one system, interpreting it, and translating it for transfer to another system. Gateways can operate at any layer of the network model and are generally more complex than switches or routers.
                        </div>
                        <div>
                            <strong class="text-sky-700">Modem:</strong> A modem (modulator/demodulator) is a network device used to convert digital signals from a computer into analog signals for transmission over communication mediums like telephone lines or cable systems, and vice-versa. Modems are typically used by consumers to access the internet via an Internet Service Provider (ISP).
                        </div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">Each network device serves a specific role in managing and directing data flow, from simple signal regeneration to complex routing between disparate networks. The placement of these devices within the layered network models (e.g., repeater at Physical Layer, switch at Data Link Layer, router at Network Layer) illustrates how different functionalities are compartmentalized to build a robust and scalable network infrastructure. This hierarchical design ensures that data is processed and forwarded efficiently at each stage of its journey across the network.</p>
                    <h4 class="text-xl font-semibold mt-8 mb-4 text-slate-900">Comparison of Network Devices</h4>
                    <div class="overflow-x-auto bg-white p-4 rounded-lg shadow-md">
                        <table class="w-full text-left">
                            <thead class="bg-slate-100">
                                <tr><th class="p-3">Device</th><th class="p-3">Primary Function</th><th class="p-3">OSI Layer</th><th class="p-3">Key Characteristics</th></tr>
                            </thead>
                            <tbody>
                                <tr class="border-b hover:bg-slate-50"><td class="p-3 font-semibold text-sky-800">Repeater</td><td class="p-3">Regenerates/amplify signals to extend network length.</td><td class="p-3">Physical (Layer 1)</td><td class="p-3">2-port device; does not filter data; extends collision domain.</td></tr>
                                <tr class="border-b hover:bg-slate-50"><td class="p-3 font-semibold text-sky-800">Hub</td><td class="p-3">Connects multiple devices; broadcasts data to all ports.</td><td class="p-3">Physical (Layer 1)</td><td class="p-3">Multi-port repeater; creates a single collision domain.</td></tr>
                                <tr class="border-b hover:bg-slate-50"><td class="p-3 font-semibold text-sky-800">Bridge</td><td class="p-3">Connects two LAN segments; filters traffic based on MAC addresses.</td><td class="p-3">Data Link (Layer 2)</td><td class="p-3">Divides collision domains; connects segments with same protocol.</td></tr>
                                <tr class="border-b hover:bg-slate-50"><td class="p-3 font-semibold text-sky-800">Switch</td><td class="p-3">Connects multiple devices; intelligently forwards data to specific port based on MAC.</td><td class="p-3">Data Link (Layer 2)</td><td class="p-3">Multi-port bridge; divides collision domains; improves efficiency.</td></tr>
                                <tr class="border-b hover:bg-slate-50"><td class="p-3 font-semibold text-sky-800">Router</td><td class="p-3">Connects different networks; forwards packets based on IP addresses; determines best path.</td><td class="p-3">Network (Layer 3)</td><td class="p-3">Divides broadcast domains; uses logical addressing.</td></tr>
                                <tr class="border-b hover:bg-slate-50"><td class="p-3 font-semibold text-sky-800">Gateway</td><td class="p-3">Connects networks using different protocols; performs protocol conversion.</td><td class="p-3">All Layers (Layer 7 often)</td><td class="p-3">Protocol converter; more complex than routers/switches.</td></tr>
                                <tr class="hover:bg-slate-50"><td class="p-3 font-semibold text-sky-800">Modem</td><td class="p-3">Converts digital signals to analog for transmission and vice-versa.</td><td class="p-3">Physical (Layer 1)</td><td class="p-3">Used for internet access over phone lines/cables.</td></tr>
                            </tbody>
                        </table>
                    </div>
                `
            },
            stop_wait: {
                title: "Stop-and-Wait Protocol",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">Stop-and-Wait Protocol</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">The Stop-and-Wait protocol is a fundamental flow control protocol used at the Data Link Layer to ensure reliable data transfer over a noisy channel. Its core principle is simplicity: the sender transmits one data packet at a time and then pauses, waiting for an acknowledgment (ACK) from the receiver before sending the next packet.</p>
                    <div class="bg-white p-6 rounded-lg shadow-md">
                        <h4 class="text-xl font-semibold mb-2 text-sky-800">Working Principle</h4>
                        <ul class="list-disc list-inside space-y-2 text-slate-600">
                            <li><strong>Sender's Side:</strong> The sender transmits a single data packet. After sending, it starts a timer and waits for an acknowledgment.</li>
                            <li><strong>Receiver's Side:</strong> Upon receiving a data packet, the receiver processes it and immediately sends an ACK back to the sender.</li>
                            <li><strong>Next Packet:</strong> The sender, upon receiving the ACK, sends the next data packet. If the timer expires before an ACK is received (indicating a lost data packet or lost ACK), the sender retransmits the original packet.</li>
                        </ul>
                        <h4 class="text-xl font-semibold mt-4 mb-2 text-sky-800">Advantages</h4>
                        <ul class="list-disc list-inside space-y-2 text-slate-600">
                            <li><strong>Simplicity:</strong> It is very easy to understand and implement, requiring minimal complex logic.</li>
                            <li><strong>Accuracy:</strong> Ensures that each data segment sent or received is the correct one in sequence, as the sender waits for confirmation before proceeding.</li>
                        </ul>
                        <h4 class="text-xl font-semibold mt-4 mb-2 text-sky-800">Disadvantages</h4>
                        <ul class="list-disc list-inside space-y-2 text-slate-600">
                            <li><strong>Low Efficiency/Utilization:</strong> This is the most significant drawback. The sender must wait for an ACK for each packet, leading to poor channel utilization, especially over long distances with high propagation delays. If 1000 packets need to be sent, they cannot be sent concurrently.</li>
                            <li><strong>Problems with Lost Data:</strong> If a data packet is lost in transit, the receiver never sends an ACK. The sender's timer eventually expires, causing a retransmission. This leads to the sender waiting indefinitely until the timeout occurs.</li>
                            <li><strong>Problems with Lost Acknowledgments:</strong> If the data packet is received but the ACK is lost, the sender's timer will expire, leading to retransmission of the <em>same</em> data packet. The receiver will then receive a duplicate, which it must discard, and re-send the ACK.</li>
                            <li><strong>Problems with Delayed Data or Acknowledgments:</strong> A delayed ACK might be mistaken for acknowledging a different packet if the sender has already retransmitted the original packet due to a timeout.</li>
                        </ul>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">The "stop-and-wait" mechanism, while functionally sound for controlling data segment transmission, is generally considered unfeasible for production networks due to its inherently poor performance. The fundamental limitation of sending only one segment at a time and waiting for its acknowledgment means that as the distance between sender and receiver increases, the propagation delay also increases, severely impacting throughput. This highlights a crucial trade-off in network protocol design: simplicity and accuracy often come at the cost of efficiency and speed, particularly in environments with significant latency. The protocol serves as an important educational tool for introducing Automatic Repeat-Request (ARQ) mechanisms, demonstrating core concepts of reliable data transfer, but its practical application is limited to scenarios where simplicity outweighs the need for high throughput.</p>
                `
            },
            transmission_modes: {
                title: "Transmission Modes",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">Transmission Modes</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">Transmission modes define the direction of data flow between two connected devices. There are three primary modes.</p>
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-4 text-center">
                        <div class="bg-white p-6 rounded-lg shadow-md">
                            <h4 class="text-xl font-semibold mb-2 text-sky-800">Simplex</h4>
                            <p class="text-slate-600">In simplex transmission mode, communication occurs in only one direction, from the sender to the receiver. The sender can only transmit data, and the receiver can only receive; there is no capability for the receiver to send a reply or feedback. This is analogous to a one-way road. An example is a keyboard sending input to a monitor; the monitor displays the input but cannot send data back to the keyboard. This mode offers the worst performance in terms of bidirectional communication.</p>
                        </div>
                        <div class="bg-white p-6 rounded-lg shadow-md">
                            <h4 class="text-xl font-semibold mb-2 text-sky-800">Half-Duplex</h4>
                            <p class="text-slate-600">In half-duplex transmission mode, communication between the sender and receiver can occur in both directions, but not simultaneously. The channel is interchangeably used by both connected devices; one device sends while the other receives, and then they switch roles. This is like a single-lane road where traffic flows in one direction at a time. A common example is a walkie-talkie, where users must take turns speaking and listening. Performance is better than simplex but still limited by the alternating nature of transmission.</p>
                        </div>
                        <div class="bg-white p-6 rounded-lg shadow-md">
                            <h4 class="text-xl font-semibold mb-2 text-sky-800">Full-Duplex</h4>
                            <p class="text-slate-600">In full-duplex transmission mode, communication between the sender and receiver can occur simultaneously in both directions. Both devices can transmit and receive data at the same time, much like a two-way road where traffic flows in both directions concurrently. A telephone conversation is a classic example, where both participants can speak and listen simultaneously. This mode offers the best performance among the three, as it maximizes bandwidth utilization.</p>
                        </div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">The choice of transmission mode directly impacts the efficiency and interactivity of communication. The progression from simplex to half-duplex and then to full-duplex reflects an increasing demand for concurrent and responsive data exchange. While simplex is suitable for simple, unidirectional data streams, half-duplex introduces bidirectional capability with a trade-off in simultaneous communication. Full-duplex, by enabling concurrent two-way data flow, significantly enhances throughput and user experience in modern networks, demonstrating how system design adapts to optimize for speed and interactivity.</p>
                    <h4 class="text-xl font-semibold mt-8 mb-4 text-slate-900">Comparison of Transmission Modes</h4>
                    <div class="overflow-x-auto bg-white p-4 rounded-lg shadow-md">
                        <table class="w-full text-left">
                            <thead class="bg-slate-100">
                                <tr>
                                    <th class="p-3">Feature</th>
                                    <th class="p-3">Simplex</th>
                                    <th class="p-3">Half-Duplex</th>
                                    <th class="p-3">Full-Duplex</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Direction of Communication</td>
                                    <td class="p-3">Unidirectional (one-way)</td>
                                    <td class="p-3">Two-directional, but one at a time</td>
                                    <td class="p-3">Two-directional, simultaneously</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Send/Receive</td>
                                    <td class="p-3">Sender only sends, receiver only receives</td>
                                    <td class="p-3">Both can send/receive, but not concurrently</td>
                                    <td class="p-3">Both can send/receive concurrently</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Performance</td>
                                    <td class="p-3">Worst performing for bidirectional needs</td>
                                    <td class="p-3">Better than Simplex, but still limited by turns</td>
                                    <td class="p-3">Best performing, maximizes bandwidth</td>
                                </tr>
                                <tr class="hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Example</td>
                                    <td class="p-3">Keyboard to Monitor, Radio broadcast</td>
                                    <td class="p-3">Walkie-talkie, CB radio</td>
                                    <td class="p-3">Telephone conversation, Ethernet (modern)</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                    <h4 class="text-xl font-semibold mt-8 mb-4 text-slate-900">Serial vs. Parallel Transmission</h4>
                    <p class="mb-6 text-slate-700 leading-relaxed">Data transmission can be broadly categorized based on how bits are sent across a medium: serially or in parallel.</p>
                    <div class="space-y-4">
                        <div>
                            <strong class="text-sky-700">Serial Transmission:</strong> In serial data transmission, bits are sent one after the other in a sequential manner, using a single (logical) data line. This is the predominant method for devices communicating over a network.
                            <ul class="list-disc list-inside ml-4 mt-2">
                                <li><strong>Advantages:</strong> Requires fewer data lines, saving physical space and reducing cabling costs. It is less susceptible to "skew" (timing differences between bits on different lines) over longer distances.</li>
                                <li><strong>Disadvantages:</strong> Generally slower than parallel transmission for the same clock rate because only one bit is sent at a time.</li>
                                <li><strong>Modes:</strong> Can be synchronous (uses a shared clock signal) or asynchronous (no shared clock, uses start/stop bits for timing).</li>
                            </ul>
                        </div>
                        <div>
                            <strong class="text-sky-700">Parallel Transmission:</strong> In parallel transmission, binary data is grouped into multiple bits (e.g., a byte) and sent simultaneously across multiple data lines. The number of data lines corresponds to the number of bits transmitted concurrently.
                            <ul class="list-disc list-inside ml-4 mt-2">
                                <li><strong>Advantages:</strong> Allows for groups of bits (bytes) to be transmitted much faster than serial transmission, increasing throughput.</li>
                                <li><strong>Disadvantages:</strong> Requires more I/O lines and physical space, making infrastructure more costly. Susceptible to "skew" over longer distances, where bits on different lines arrive at slightly different times, limiting its effective range.</li>
                                <li><strong>Usage:</strong> Primarily used for short-distance communication within devices, such as between a computer processor and memory. Converters (serial to parallel and parallel to serial) are used at the interface between a device and a network line.</li>
                            </ul>
                        </div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">The distinction between serial and parallel transmission highlights a fundamental design trade-off between speed and complexity/cost. While parallel transmission offers higher throughput over short distances by sending multiple bits simultaneously, it demands more physical lines and is prone to synchronization issues over longer distances. Serial transmission, despite being slower bit-by-bit, is more robust over long distances due to fewer lines and simpler synchronization, making it the preferred method for network communication. This illustrates how engineering solutions are chosen based on specific application requirements and physical constraints.</p>
                `
            },
            media: {
                title: "Guided & Unguided Media",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">Transmission Media</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">Transmission media are the physical paths through which data travels from source to destination. They are broadly classified as guided or unguided.</p>
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                        <div class="bg-white p-6 rounded-lg shadow-md">
                            <h4 class="text-xl font-semibold mb-2 text-sky-800">Guided Media (Bounded Media)</h4>
                            <p class="mb-2 text-slate-600">Guided media refers to physical pathways through which signals are transmitted, providing a conduit from one machine to another. The signal energy is communicated via physical wires or cables.</p>
                            <ul class="list-disc list-inside ml-4 text-slate-600">
                                <li><strong>Characteristics:</strong> Signals are confined to a specific physical path. Generally preferred for direct, point-to-point, or point-to-multipoint communication where physical cabling is feasible. Signals are typically in the state of current and voltage. Transmission capacity can be increased by adding more wires.</li>
                                <li><strong>Types:</strong>
                                    <ul class="list-circle list-inside ml-8 text-slate-600">
                                        <li><strong>Twisted-Pair Cable:</strong> Consists of pairs of insulated wires twisted together to reduce electromagnetic interference. Used in Ethernet networks.</li>
                                        <li><strong>Coaxial Cable:</strong> Features a central conductor surrounded by an insulating layer, a metallic shield, and an outer insulating jacket. Used in cable television and older Ethernet networks.</li>
                                        <li><strong>Optical Fiber Cable:</strong> Transmits data as pulses of light through thin strands of glass or plastic. Offers very high bandwidth and long-distance transmission with minimal signal loss.</li>
                                        <li><strong>Open Wire:</strong> Older, less common form, simply bare wires.</li>
                                    </ul>
                                </li>
                            </ul>
                        </div>
                        <div class="bg-white p-6 rounded-lg shadow-md">
                            <h4 class="text-xl font-semibold mb-2 text-sky-800">Unguided Media (Unbounded Media/Wireless Transmission)</h4>
                            <p class="mb-2 text-slate-600">Unguided transmission media involve techniques that allow the transmission of electromagnetic waves through a wireless medium, typically air, without using any physical conduit. This medium provides a mechanism for transferring electromagnetic waves but does not direct them along a specific path.</p>
                            <ul class="list-disc list-inside ml-4 text-slate-600">
                                <li><strong>Characteristics:</strong> Signals propagate freely through the atmosphere or space. Generally preferred for broadcast communication in all directions. Signals are in the state of electromagnetic waves. Increasing capacity is often not as straightforward as adding more physical lines.</li>
                                <li><strong>Types:</strong>
                                    <ul class="list-circle list-inside ml-8 text-slate-600">
                                        <li><strong>Microwave Transmission:</strong> Uses high-frequency radio waves for line-of-sight communication, often via parabolic antennas. Used for long-distance communication and cellular networks.</li>
                                        <li><strong>Radio Transmission:</strong> Uses radio waves for broadcasting over wider areas. Used in radio, television, and wireless LANs (Wi-Fi).</li>
                                        <li><strong>Infrared Transmission:</strong> Uses infrared light for short-range, line-of-sight communication, often within a room. Used in remote controls and some short-range wireless devices.</li>
                                    </ul>
                                </li>
                            </ul>
                        </div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">The fundamental difference between guided and unguided media lies in their approach to signal containment and direction. Guided media offers controlled, high-bandwidth communication over fixed paths, making it suitable for structured network infrastructures where physical cabling is practical. Unguided media, conversely, provides flexibility and mobility by broadcasting signals wirelessly, making it ideal for mobile devices and wide-area distribution where physical connections are impractical. This distinction underscores how network designers select transmission media based on factors like distance, environment, bandwidth requirements, and the need for mobility or fixed infrastructure.</p>
                    <h4 class="text-xl font-semibold mt-8 mb-4 text-slate-900">Comparison of Guided and Unguided Media</h4>
                    <div class="overflow-x-auto bg-white p-4 rounded-lg shadow-md">
                        <table class="w-full text-left">
                            <thead class="bg-slate-100">
                                <tr>
                                    <th class="p-3">Feature</th>
                                    <th class="p-3">Guided Media</th>
                                    <th class="p-3">Unguided Media</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Physical Medium</td>
                                    <td class="p-3">Uses physical cables/wires (e.g., copper, fiber optic)</td>
                                    <td class="p-3">Uses air/space (electromagnetic waves)</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Signal Confinement</td>
                                    <td class="p-3">Signals are confined to the cable</td>
                                    <td class="p-3">Signals propagate freely</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Directionality</td>
                                    <td class="p-3">Generally point-to-point or specific paths</td>
                                    <td class="p-3">Omni-directional (broadcast) or directional (line-of-sight)</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Signal Type</td>
                                    <td class="p-3">Current and voltage signals</td>
                                    <td class="p-3">Electromagnetic waves</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Interference</td>
                                    <td class="p-3">Less susceptible to external interference (shielded)</td>
                                    <td class="p-3">More susceptible to interference (e.g., atmospheric, other signals)</td>
                                </tr>
                                <tr class="border-b hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Security</td>
                                    <td class="p-3">More secure (physical access needed for tapping)</td>
                                    <td class="p-3">Less secure (signals can be intercepted easily)</td>
                                </tr>
                                <tr class="hover:bg-slate-50">
                                    <td class="p-3 font-semibold text-sky-800">Cost</td>
                                    <td class="p-3">Higher installation cost for cabling</td>
                                    <td class="p-3">Lower installation cost for wireless, but equipment can be costly</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                `
            },
            www_ftp_http: {
                title: "WWW, FTP, HTTP",
                content: `
                    <h3 class="text-2xl font-bold mb-4 text-slate-900">WWW, FTP, and HTTP</h3>
                    <p class="mb-6 text-slate-700 leading-relaxed">These are application-layer protocols and services that are fundamental to how information is accessed and exchanged over the Internet.</p>
                    <div class="space-y-6">
                        <div>
                            <strong class="text-sky-700">WWW (World Wide Web):</strong> The World Wide Web, often simply called "The Web," is a global system of interconnected hypertext documents and other web resources, accessible via the Internet. It was invented by Sir Tim Berners-Lee and has been widely available since 1991. The Web is a service that runs <em>on</em> the Internet, which is the underlying global network infrastructure. It combines all users and resources that utilize HTTP (or HTTPS). When a URL includes "www," it indicates that the website uses HTTP. While not technically mandatory for a website (domains can exist without "www"), its widespread historical use has made it a common convention.
                        </div>
                        <div>
                            <strong class="text-sky-700">FTP (File Transfer Protocol):</strong> FTP is a standard communication protocol used for the transfer of computer files from a server to a client on a computer network. It is built on a client-server model architecture and uses separate control and data connections between the client and the server. FTP enables users to upload files to a server, download files from a server, or transfer data between computers on a local network. It is commonly used for tasks like website publishing (uploading web pages to a server) or sharing large files.
                        </div>
                        <div>
                            <strong class="text-sky-700">HTTP (Hypertext Transfer Protocol):</strong> HTTP is the foundation of the World Wide Web and is an application layer protocol designed to transfer information, specifically hypertext documents, between networked devices. It defines how messages are formatted and transmitted, and what actions web servers and browsers should take in response to various commands. HTTP operates on a request-response paradigm: a client (e.g., a web browser) makes a request to a server, which then sends a response message containing the requested content (e.g., HTML, images) and status information. HTTP is a "stateless" protocol, meaning each command runs independently of any other command, although newer versions (HTTP 1.1 and above) allow for persistent TCP connections to improve resource consumption. HTTP relies on an underlying network-layer protocol like TCP to function. HTTPS (HTTP Secure) is a secure version of HTTP that encrypts communications using Transport Layer Security (TLS) or Secure Sockets Layer (SSL).
                        </div>
                    </div>
                    <p class="mt-6 text-slate-700 leading-relaxed">These three concepts are deeply interconnected and illustrate the layered functionality of the Internet. The World Wide Web represents the vast collection of interconnected documents and resources, with HTTP serving as its fundamental "language" for communication between web servers and browsers. FTP, while also a transfer protocol, specializes in the direct movement of files rather than the hypertext-based interaction of the Web. The relationship between WWW and HTTP highlights how a broad service (the Web) is built upon a specific application-layer protocol (HTTP), demonstrating the principle of protocol layering in action. The evolution from basic file transfer (FTP) to dynamic, linked information retrieval (WWW via HTTP) reflects the increasing complexity and interactivity of online content.</p>
                `
            }
        }
    }
};

const processStateDescriptions = {
    'state-new': '<strong>New:</strong> This is the initial state where a program is in the process of being loaded from secondary memory (disk) into primary memory (RAM) to become an active process. At this stage, it typically resides in a job queue, awaiting admission to the system.',
    'state-ready': '<strong>Ready:</strong> Once a process is loaded into main memory, it enters the ready state. In this state, the process is prepared to execute and is awaiting the CPU to be allocated to it. Processes in the ready state are typically held in a ready queue.',
    'state-running': '<strong>Running:</strong> In the running state, the CPU is actively executing the process\'s instructions. On a single CPU core, only one process can be in the running state at any given moment.',
    'state-waiting': '<strong>Waiting/Blocked:</strong> A process transitions to the waiting or blocked state when it is temporarily suspended from execution. This suspension occurs because the process is awaiting the completion of some event, such as an I/O operation, the availability of a specific resource, or user input. While waiting, the process is typically moved to a device-specific queue.',
    'state-terminated': '<strong>Terminated:</strong> The terminated state signifies that a process has completed its execution, or it has been explicitly aborted by the operating system. Upon termination, all resources previously allocated to the process are deallocated.'
};

const modelLayerDescriptions = {
    osi: {
        app: '<strong>Application (OSI Layer 7):</strong> This is the closest layer to the end user, providing network services directly to applications. It includes protocols for resource sharing, remote file access, email, and web browsing (e.g., HTTP, FTP, SMTP).',
        pres: '<strong>Presentation (OSI Layer 6):</strong> Responsible for data format translation, encryption, and compression, ensuring that data is presented in a format understandable by the application layer of the receiving system.',
        sess: '<strong>Session (OSI Layer 5):</strong> Establishes, manages, and terminates communication sessions between applications. It provides synchronization and dialog control, handling session checkpointing and recovery.',
        trans: '<strong>Transport (OSI Layer 4):</strong> Ensures reliable, end-to-end data transfer between host systems. It manages error correction, data flow control, and retransmission of lost data. This layer can be connection-oriented (like TCP, which uses <strong>segments</strong>) or connectionless (like UDP, which uses <strong>datagrams</strong>).',
        net: '<strong>Network (OSI Layer 3):</strong> Responsible for logical addressing (IP addresses) and routing packets across different networks. It determines the best path for data delivery and handles packet forwarding and fragmentation if necessary.',
        data: '<strong>Data Link (OSI Layer 2):</strong> This layer provides reliable data transfer across a direct link. It handles framing (dividing data into frames), physical addressing (MAC addresses), error detection, and flow control. It has two sublayers: Logical Link Control (for flow control and error detection) and Media Access Control (for hardware addressing and access methods). The PDU at this layer is a <strong>frame</strong>.',
        phys: '<strong>Physical (OSI Layer 1):</strong> This is the lowest layer, responsible for the physical transmission of raw bit streams over the network medium. It defines hardware specifications, cabling, connectors, voltage levels, and data rates. The PDU (Protocol Data Unit) at this layer is a <strong>bit</strong> or a stream of bits.',
    },
    tcpip: {
        app: '<strong>Application (TCP/IP):</strong> Combines OSI layers 5, 6, and 7. Handles user-facing protocols like HTTP and FTP. It defines protocols for node-to-node application communication and provides services directly to application software running on a computer.',
        trans: '<strong>Transport (TCP/IP):</strong> Corresponds to OSI Transport layer. Manages host-to-host communication with TCP and UDP. It defines protocols for setting the level of transmission service for applications and is responsible for reliable transmission and error-free delivery.',
        net: '<strong>Internet (TCP/IP):</strong> Corresponds to OSI Network layer. Uses the Internet Protocol (IP) for addressing and routing. This layer defines protocols for logically transmitting packets over the network, handling device addressing, routing, and path determination.',
        link: '<strong>Network Access (TCP/IP):</strong> Combines OSI layers 1 and 2. Handles all hardware details of physical interfacing. It defines the protocols and hardware required to deliver data across a physical network, handling physical addressing, framing, and access to the network medium.',
    }
};

document.addEventListener('DOMContentLoaded', () => {
    const osNav = document.querySelector('[data-subject="os"]');
    const cnNav = document.querySelector('[data-subject="cn"]');
    const contentDisplay = document.getElementById('content-display');
    const welcomeMessage = document.getElementById('welcome-message');
    const darkModeToggle = document.getElementById('dark-mode-toggle');
    const darkModeIcon = document.getElementById('dark-mode-icon');
    let currentChart = null;

    function populateNav(subject, navElement) {
        const topics = data[subject].topics;
        for (const key in topics) {
            const topic = topics[key];
            const li = document.createElement('li');
            li.innerHTML = `<a href="#" class="sub-nav-link block p-3 rounded-md hover:bg-sky-100 transition-colors" data-subject="${subject}" data-topic="${key}">${topic.title}</a>`;
            navElement.appendChild(li);
        }
    }

    populateNav('os', osNav);
    populateNav('cn', cnNav);

    function showContent(subject, topicKey) {
        welcomeMessage.style.display = 'none';
        contentDisplay.style.display = 'block';
        contentDisplay.innerHTML = data[subject].topics[topicKey].content;

        document.querySelectorAll('.sub-nav-link').forEach(link => link.classList.remove('active'));
        document.querySelector(`.sub-nav-link[data-subject="${subject}"][data-topic="${topicKey}"]`).classList.add('active');

        if (topicKey === 'process_state') initProcessStateDiagram();
        if (topicKey === 'disk_scheduling') initDiskSchedulingSim();
        if (topicKey === 'osi_model') initModelComparator();
    }

    document.querySelectorAll('.sub-nav-link').forEach(link => {
        link.addEventListener('click', (e) => {
            e.preventDefault();
            const subject = e.target.dataset.subject;
            const topicKey = e.target.dataset.topic;
            showContent(subject, topicKey);
        });
    });

    const btnOs = document.getElementById('btn-os');
    const btnCn = document.getElementById('btn-cn');
    const osNavContainer = document.getElementById('os-nav');
    const cnNavContainer = document.getElementById('cn-nav');

    function switchSubject(subject) {
        if (subject === 'os') {
            btnOs.classList.add('active');
            btnCn.classList.remove('active');
            osNavContainer.classList.add('active');
            cnNavContainer.classList.remove('active');
        } else {
            btnCn.classList.add('active');
            btnOs.classList.remove('active');
            cnNavContainer.classList.add('active');
            osNavContainer.classList.remove('active');
        }
        welcomeMessage.style.display = 'block';
        contentDisplay.style.display = 'none';
        // Clear active sub-nav links when switching main subject
        document.querySelectorAll('.sub-nav-link').forEach(link => link.classList.remove('active'));
    }

    btnOs.addEventListener('click', () => switchSubject('os'));
    btnCn.addEventListener('click', () => switchSubject('cn'));
    
    switchSubject('os'); // Default to OS on load

    function initProcessStateDiagram() {
        const states = document.querySelectorAll('.process-state');
        const infoBox = document.getElementById('process-state-info');
        states.forEach(state => {
            state.addEventListener('click', () => {
                states.forEach(s => s.classList.remove('highlighted'));
                state.classList.add('highlighted');
                infoBox.innerHTML = processStateDescriptions[state.id];
            });
        });
    }

    function initModelComparator() {
        const osiLayers = document.querySelectorAll('#osi-layers .model-layer');
        const tcpipLayers = document.querySelectorAll('#tcpip-layers .model-layer');
        const infoBox = document.getElementById('model-info');

        function handleHover(e, model) {
            const layerKey = e.target.dataset.layer;
            const mapKeys = e.target.dataset.map.split(',');
            
            osiLayers.forEach(l => l.style.backgroundColor = ''); // Clear previous highlights
            tcpipLayers.forEach(l => l.style.backgroundColor = ''); // Clear previous highlights

            if (model === 'osi') {
                e.target.style.backgroundColor = '#e0f2fe'; // Light blue for hovered OSI
                tcpipLayers.forEach(l => {
                    if (mapKeys.includes(l.dataset.layer)) l.style.backgroundColor = '#bae6fd'; // Lighter blue for mapped TCP/IP
                });
            } else { // tcpip
                e.target.style.backgroundColor = '#e0f2fe'; // Light blue for hovered TCP/IP
                 osiLayers.forEach(l => {
                    if (mapKeys.includes(l.dataset.layer)) l.style.backgroundColor = '#bae6fd'; // Lighter blue for mapped OSI
                });
            }
            infoBox.innerHTML = modelLayerDescriptions[model][layerKey];
        }

        function handleLeave() {
            osiLayers.forEach(l => l.style.backgroundColor = '');
            tcpipLayers.forEach(l => l.style.backgroundColor = '');
            infoBox.innerHTML = '<p class="text-slate-600">Hover over a layer to learn more.</p>';
        }

        osiLayers.forEach(layer => {
            layer.addEventListener('mouseover', (e) => handleHover(e, 'osi'));
            layer.addEventListener('mouseleave', handleLeave);
        });
        tcpipLayers.forEach(layer => {
            layer.addEventListener('mouseover', (e) => handleHover(e, 'tcpip'));
            layer.addEventListener('mouseleave', handleLeave);
        });
    }

    function initDiskSchedulingSim() {
        const runBtn = document.getElementById('run-sim');
        runBtn.removeEventListener('click', runSimulation); // Remove old listener to prevent duplicates
        runBtn.addEventListener('click', runSimulation);
        // Run simulation with default values on load of the section
        runSimulation();
    }
    
    function runSimulation() {
        const requestsInput = document.getElementById('requests').value;
        const startPos = parseInt(document.getElementById('startPos').value);
        const algorithm = document.getElementById('algorithm').value;
        const resultsDiv = document.getElementById('sim-results');
        
        let requests = requestsInput.split(',').map(n => parseInt(n.trim())).filter(n => !isNaN(n) && n >= 0 && n < 200);
        if (requests.length === 0) {
            resultsDiv.textContent = "Please enter a valid request queue (numbers between 0-199, comma-separated).";
            if (currentChart) currentChart.destroy();
            return;
        }
        if (isNaN(startPos) || startPos < 0 || startPos >= 200) {
            resultsDiv.textContent = "Please enter a valid start position (number between 0-199).";
            if (currentChart) currentChart.destroy();
            return;
        }

        let sequence = [startPos];
        let totalMovement = 0;
        let workQueue = [...requests];
        let currentPos = startPos;

        switch (algorithm) {
            case 'fcfs':
                sequence = sequence.concat(workQueue);
                break;
            case 'sstf':
                while (workQueue.length > 0) {
                    let closest = -1;
                    let minDistance = Infinity;
                    let closestIndex = -1;

                    workQueue.forEach((req, index) => {
                        const distance = Math.abs(req - currentPos);
                        if (distance < minDistance) {
                            minDistance = distance;
                            closest = req;
                            closestIndex = index;
                        }
                    });
                    currentPos = closest;
                    sequence.push(currentPos);
                    workQueue.splice(closestIndex, 1);
                }
                break;
            case 'scan':
            case 'c-scan':
            case 'look':
            case 'c-look':
                workQueue.sort((a, b) => a - b);
                let left = workQueue.filter(r => r < startPos).sort((a,b) => b-a); // Descending for left sweep
                let right = workQueue.filter(r => r >= startPos).sort((a,b) => a-b); // Ascending for right sweep

                if (algorithm === 'scan') {
                    // Go right first
                    sequence = sequence.concat(right);
                    // If not at end, go to end
                    if (right.length > 0 && right[right.length - 1] < 199) sequence.push(199);
                    // Then go left
                    sequence = sequence.concat(left);
                }
                if (algorithm === 'c-scan') {
                    // Go right first
                    sequence = sequence.concat(right);
                    // Go to end (199) if not there and there were requests on right
                    if (right.length > 0 && right[right.length - 1] < 199) sequence.push(199);
                    // Jump to 0 without servicing
                    if (left.length > 0) sequence.push(0);
                    // Then go right from 0 (which means servicing the original 'left' requests in ascending order)
                    sequence = sequence.concat(left.sort((a,b) => a-b));
                }
                if (algorithm === 'look') {
                    // Go right first
                    sequence = sequence.concat(right);
                    // Then go left
                    sequence = sequence.concat(left);
                }
                if (algorithm === 'c-look') {
                    // Go right first
                    sequence = sequence.concat(right);
                    // Jump to the smallest request on the left without servicing
                    if (left.length > 0) sequence.push(left[left.length - 1]); // Smallest element in 'left' after reverse sort
                    // Then go right (servicing original 'left' requests in ascending order)
                    sequence = sequence.concat(left.sort((a,b) => a-b));
                }
                break;
        }

        for (let i = 0; i < sequence.length - 1; i++) {
            totalMovement += Math.abs(sequence[i+1] - sequence[i]);
        }

        resultsDiv.innerHTML = `Service Order: <span class="text-sky-700">${sequence.join(' â†’ ')}</span><br>Total Head Movement: <span class="text-sky-700">${totalMovement}</span>`;
        drawDiskChart(sequence, algorithm);
    }
    
    function drawDiskChart(sequence, title) {
        const ctx = document.getElementById('disk-chart').getContext('2d');
        if (currentChart) {
            currentChart.destroy();
        }
        currentChart = new Chart(ctx, {
            type: 'line',
            data: {
                labels: sequence.map((_, i) => i),
                datasets: [{
                    label: `Head Movement (${title.toUpperCase()})`,
                    data: sequence,
                    borderColor: '#0284c7',
                    backgroundColor: 'rgba(2, 132, 199, 0.1)',
                    fill: false,
                    pointRadius: 5,
                    pointBackgroundColor: '#0ea5e9'
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    y: {
                        beginAtZero: true,
                        max: 200,
                        title: { display: true, text: 'Cylinder Number' }
                    },
                    x: {
                        title: { display: true, text: 'Service Step' }
                    }
                },
                plugins: {
                    legend: {
                        display: true
                    }
                }
            }
        });
    }

    // Dark Mode Logic
    function enableDarkMode() {
        document.body.classList.add('dark-mode');
        darkModeIcon.textContent = 'â˜€ï¸'; // Sun icon for light mode
        localStorage.setItem('theme', 'dark');
    }

    function disableDarkMode() {
        document.body.classList.remove('dark-mode');
        darkModeIcon.textContent = 'ðŸŒ™'; // Moon icon for dark mode
        localStorage.setItem('theme', 'light');
    }

    // Check for saved theme preference
    const savedTheme = localStorage.getItem('theme');
    if (savedTheme === 'dark') {
        enableDarkMode();
    } else {
        disableDarkMode(); // Ensure light mode is default or explicitly set
    }

    darkModeToggle.addEventListener('click', () => {
        if (document.body.classList.contains('dark-mode')) {
            disableDarkMode();
        } else {
            enableDarkMode();
        }
    });

});
</script>
</body>
</html>
